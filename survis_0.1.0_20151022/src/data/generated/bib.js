define({ entries : {
    "chatterjee-etal-2022-accurate": {
        "abstract": "\"Online alignment in machine translation refers to the task of aligning a target word to a source word when the target sequence has only been partially decoded. Good online alignments facilitate important applications such as lexically constrained translation where user-defined dictionaries are used to inject lexical constraints into the translation model. We propose a novel posterior alignment technique that is truly online in its execution and superior in terms of alignment error rates compared to existing methods. Our proposed inference technique jointly considers alignment and token probabilities in a principled manner and can be seamlessly integrated within existing constrained beam-search decoding algorithms. On five language pairs, including two distant language pairs, we achieve consistent drop in alignment error rates. When deployed on seven lexically constrained translation tasks, we achieve significant improvements in BLEU specifically around the constrained positions.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Chatterjee, Soumya  and Sarawagi, Sunita  and Jyothi, Preethi\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.460\",",
        "month": "may,",
        "pages": "\"6675--6689\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"Accurate Online Posterior Alignments for Principled Lexically-Constrained Decoding\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.460\",",
        "year": "\"2022\","
    },
    "he-yiu-2022-controllable": {
        "abstract": "\"Example sentences for targeted words in a dictionary play an important role to help readers understand the usage of words. Traditionally, example sentences in a dictionary are usually created by linguistics experts, which are labor-intensive and knowledge-intensive. In this paper, we introduce the problem of dictionary example sentence generation, aiming to automatically generate dictionary example sentences for targeted words according to the corresponding definitions. This task is challenging especially for polysemous words, because the generated sentences need to reflect different usages and meanings of these targeted words. Targeted readers may also have different backgrounds and educational levels. It is essential to generate example sentences that can be understandable for different backgrounds and levels of audiences. To solve these problems, we propose a controllable target-word-aware model for this task. Our proposed model can generate reasonable examples for targeted words, even for polysemous words. In addition, our model allows users to provide explicit control over attributes related to readability, such as length and lexical complexity, thus generating suitable examples for targeted audiences. Automatic and human evaluations on the Oxford dictionary dataset show that our model can generate suitable examples for targeted words with specific definitions while meeting the desired readability.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"He, Xingwei  and Yiu, Siu Ming\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.46\",",
        "month": "may,",
        "pages": "\"610--627\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"Controllable Dictionary Example Generation: Generating Example Sentences for Specific Targeted Audiences\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.46\",",
        "year": "\"2022\","
    },
    "jiaxin-etal-2022-compiling": {
        "abstract": "\"{``}The definition generation task aims to generate a word{'}s definition within a specific context automatically. However, owing to the lack of datasets for different complexities, the definitions produced by models tend to keep the same complexity level. This paper proposes a novel task of generating definitions for a word with controllable complexity levels. Correspondingly, we introduce COMPILING, a dataset given detailed information about Chinese definitions, and each definition is labeled with its complexity levels. The COMPILING dataset includes 74,303 words and 106,882 definitions. To the best of our knowledge, it is the largest dataset of the Chinese definition generation task. We select various representative generation methods as baselines for this task and conduct evaluations, which illustrates that our dataset plays an outstanding role in assisting models in generating different complexity-level definitions. We believe that the COMPILING dataset will benefit further research in complexity controllable definition generation.{''}\",",
        "address": "\"Nanchang, China\",",
        "author": "\"Jiaxin, Yuan  and Cunliang, Kong  and Chenhui, Xie  and Liner, Yang  and Erhong, Yang\",",
        "booktitle": "\"Proceedings of the 21st Chinese National Conference on Computational Linguistics\",",
        "language": "\"English\",",
        "month": "oct,",
        "pages": "\"921--931\",",
        "publisher": "\"Chinese Information Processing Society of China\",",
        "title": "\"{COMPILING}: A Benchmark Dataset for {C}hinese Complexity Controllable Definition Generation\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.ccl-1.81\",",
        "year": "\"2022\","
    },
    "ke-etal-2022-ctrleval": {
        "abstract": "\"Existing reference-free metrics have obvious limitations for evaluating controlled text generation models. Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets. In this paper, we propose an unsupervised reference-free metric called CTRLEval, which evaluates controlled text generation from different aspects by formulating each aspect into multiple text infilling tasks. On top of these tasks, the metric assembles the generation probabilities from a pre-trained language model without any model training. Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Ke, Pei  and Zhou, Hao  and Lin, Yankai  and Li, Peng  and Zhou, Jie  and Zhu, Xiaoyan  and Huang, Minlie\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.164\",",
        "month": "may,",
        "pages": "\"2306--2319\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"{CTRLE}val: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.164\",",
        "year": "\"2022\","
    },
    "liu-etal-2022-token": {
        "abstract": "\"Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications. Existing work usually attempts to detect these hallucinations based on a corresponding oracle reference at a sentence or document level. However ground-truth references may not be readily available for many free-form text generation applications, and sentence- or document-level detection may fail to provide the fine-grained signals that would prevent fallacious content in real time. As a first step to addressing these issues, we propose a novel token-level, reference-free hallucination detection task and an associated annotated dataset named HaDeS (HAllucination DEtection dataSet). To create this dataset, we first perturb a large number of text segments extracted from English language Wikipedia, and then verify these with crowd-sourced annotations. To mitigate label imbalance during annotation, we utilize an iterative model-in-loop strategy. We conduct comprehensive data analyses and create multiple baseline models.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Liu, Tianyu  and Zhang, Yizhe  and Brockett, Chris  and Mao, Yi  and Sui, Zhifang  and Chen, Weizhu  and Dolan, Bill\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.464\",",
        "month": "may,",
        "pages": "\"6723--6737\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.464\",",
        "year": "\"2022\","
    },
    "mohankumar-khapra-2022-active": {
        "abstract": "\"Recent studies have shown the advantages of evaluating NLG systems using pairwise comparisons as opposed to direct assessment. Given $k$ systems, a naive approach for identifying the top-ranked system would be to uniformly obtain pairwise comparisons from all ${k \\choose 2}$ pairs of systems. However, this can be very expensive as the number of human annotations required would grow quadratically with $k$. In this work, we introduce Active Evaluation, a framework to efficiently identify the top-ranked system by actively choosing system pairs for comparison using dueling bandit algorithms. We perform extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation datasets spanning 5 tasks and show that the number of human annotations can be reduced by 80{\\%}. To further reduce the number of human annotations, we propose model-based dueling bandit algorithms which combine automatic evaluation metrics with human evaluations. Specifically, we eliminate sub-optimal systems even before the human annotation process and perform human evaluations only on test examples where the automatic metric is highly uncertain. This reduces the number of human annotations required further by 89{\\%}. In effect, we show that identifying the top-ranked system requires only a few hundred human annotations, which grow linearly with $k$. Lastly, we provide practical recommendations and best practices to identify the top-ranked system efficiently. Our code has been made publicly available at https://github.com/akashkm99/duelnlg\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Mohankumar, Akash Kumar  and Khapra, Mitesh\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.600\",",
        "month": "may,",
        "pages": "\"8761--8781\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"Active Evaluation: Efficient {NLG} Evaluation with Few Pairwise Comparisons\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.600\",",
        "year": "\"2022\","
    },
    "nagoudi-etal-2022-arat5": {
        "abstract": "\"Transfer learning with a unified Transformer framework (T5) that converts all language problems into a text-to-text format was recently proposed as a simple and effective transfer learning approach. Although a multilingual version of the T5 model (mT5) was also introduced, it is not clear how well it can fare on non-English tasks involving diverse data. To investigate this question, we apply mT5 on a language with a wide variety of dialects{--}Arabic. For evaluation, we introduce a novel benchmark for ARabic language GENeration (ARGEN), covering seven important tasks. For model comparison, we pre-train three powerful Arabic T5-style models and evaluate them on ARGEN. Although pre-trained with {\\textasciitilde}49 less data, our new models perform significantly better than mT5 on all ARGEN tasks (in 52 out of 59 test sets) and set several new SOTAs. Our models also establish new SOTA on the recently-proposed, large Arabic language understanding evaluation benchmark ARLUE (Abdul-Mageed et al., 2021). Our new models are publicly available. We also link to ARGEN datasets through our repository: https://github.com/UBC-NLP/araT5.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Nagoudi, El Moatez Billah  and Elmadany, AbdelRahim  and Abdul-Mageed, Muhammad\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.47\",",
        "month": "may,",
        "pages": "\"628--647\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"{A}ra{T}5: Text-to-Text Transformers for {A}rabic Language Generation\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.47\",",
        "year": "\"2022\","
    },
    "narayan-etal-2022-well": {
        "abstract": "\"We propose Composition Sampling, a simple but effective method to generate diverse outputs for conditional generation of higher quality compared to previous stochastic decoding strategies. It builds on recently proposed plan-based neural generation models (FROST, Narayan et al, 2021) that are trained to first create a composition of the output and then generate by conditioning on it and the input. Our approach avoids text degeneration by first sampling a composition in the form of an entity chain and then using beam search to generate the best possible text grounded to this entity chain. Experiments on summarization (CNN/DailyMail and XSum) and question generation (SQuAD), using existing and newly proposed automaticmetrics together with human-based evaluation, demonstrate that Composition Sampling is currently the best available decoding strategy for generating diverse meaningful outputs.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Narayan, Shashi  and Sim{\\~o}es, Gon{\\c{c}}alo  and Zhao, Yao  and Maynez, Joshua  and Das, Dipanjan  and Collins, Michael  and Lapata, Mirella\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.94\",",
        "month": "may,",
        "pages": "\"1319--1339\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"A Well-Composed Text is Half Done! Composition Sampling for Diverse Conditional Generation\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.94\",",
        "year": "\"2022\","
    },
    "yin-wan-2022-seq2seq": {
        "abstract": "\"With the rapid development of deep learning, Seq2Seq paradigm has become prevalent for end-to-end data-to-text generation, and the BLEU scores have been increasing in recent years. However, it is widely recognized that there is still a gap between the quality of the texts generated by models and the texts written by human. In order to better understand the ability of Seq2Seq models, evaluate their performance and analyze the results, we choose to use Multidimensional Quality Metric(MQM) to evaluate several representative Seq2Seq models on end-to-end data-to-text generation. We annotate the outputs of five models on four datasets with eight error types and find that 1) copy mechanism is helpful for the improvement in Omission and Inaccuracy Extrinsic errors but it increases other types of errors such as Addition; 2) pre-training techniques are highly effective, and pre-training strategy and model size are very significant; 3) the structure of the dataset also influences the model{'}s performance greatly; 4) some specific types of errors are generally challenging for seq2seq models.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Yin, Xunjian  and Wan, Xiaojun\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.531\",",
        "month": "may,",
        "pages": "\"7701--7710\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"How Do {S}eq2{S}eq Models Perform on End-to-End Data-to-Text Generation?\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.531\",",
        "year": "\"2022\","
    },
    "zhang-etal-2022-continual": {
        "abstract": "\"Continual learning is essential for real-world deployment when there is a need to quickly adapt the model to new tasks without forgetting knowledge of old tasks. Existing work on continual sequence generation either always reuses existing parameters to learn new tasks, which is vulnerable to catastrophic forgetting on dissimilar tasks, or blindly adds new parameters for every new task, which could prevent knowledge sharing between similar tasks. To get the best of both worlds, in this work, we propose continual sequence generation with adaptive compositional modules to adaptively add modules in transformer architectures and compose both old and new modules for new tasks. We also incorporate pseudo experience replay to facilitate knowledge transfer in those shared modules. Experiment results on various sequences of generation tasks show that our framework can adaptively add modules or reuse modules based on task similarity, outperforming state-of-the-art baselines in terms of both performance and parameter efficiency. We make our code public at https://github.com/GT-SALT/Adaptive-Compositional-Modules.\",",
        "address": "\"Dublin, Ireland\",",
        "author": "\"Zhang, Yanzhe  and Wang, Xuezhi  and Yang, Diyi\",",
        "booktitle": "\"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",",
        "doi": "\"10.18653/v1/2022.acl-long.255\",",
        "month": "may,",
        "pages": "\"3653--3667\",",
        "publisher": "\"Association for Computational Linguistics\",",
        "title": "\"Continual Sequence Generation with Adaptive Compositional Modules\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.acl-long.255\",",
        "year": "\"2022\","
    }
}});